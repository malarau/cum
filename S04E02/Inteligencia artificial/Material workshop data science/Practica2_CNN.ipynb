{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image classification with a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaria cell classification\n",
    "\n",
    "Malaria is a blood disease caused by the *Plasmodium* parasite, and is transmitted through the bite of the female *Anopheles* mosquito. The disease is mostly diagnosed by counting parasitized blood cells in a blood smear under a microscope. However, manual cell counting is an exhausting, error-prone procedure. This can negatively affect the quality of the diagnosis [[1]](https://peerj.com/articles/4568/). Especially in *resource-constrained* regions of the world, difficult working conditions lead to poor diagnosis quality [[2]](https://lhncbc.nlm.nih.gov/publication/pub9932) .\n",
    "\n",
    "In this practical session we will develop a deep learning pipeline that will aid in improving malaria diagnosis by automating infected cell counting. To this end we will use the Malaria cell dataset [[2]](https://lhncbc.nlm.nih.gov/publication/pub9932) to train a neural network that predicts a cell's infection state based on a microscopy image of it. The microscopy images were acquired using a smartphone attached to a small portable microscope.\n",
    "\n",
    "To set up the deep learning pipeline we will go through these steps:\n",
    "- Load the dataset\n",
    "- Preprocess the dataset\n",
    "- Define a neural network\n",
    "- Define the learning procedure\n",
    "- Train the neural network\n",
    "- Inspect the network's performance\n",
    "\n",
    "We will use the [TensorFlow machine learning framework](http://tensorflow.org) to implement these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def select_device(prefer_gpu=True):\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    gpus = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    if (len(gpus) > 0) and prefer_gpu:\n",
    "        return gpus[0]\n",
    "    else:\n",
    "        return [x.name for x in local_device_protos if x.device_type == 'CPU'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code sets the device to use to GPU if you have one available\n",
    "device = select_device(prefer_gpu=True)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above `device` is used in the notebook to select where code is executed. This is done with a `with`-statement:\n",
    "```\n",
    "with tf.device(device):\n",
    "    # code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Malaria dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `tensorflow-datasets` package to load the malaria dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has been recently moved and tensorflow-datasets hasn't been updated yet,\n",
    "# so we update the URL manually\n",
    "tfds.image_classification.malaria._URL=\"https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\"\n",
    "\n",
    "# Now we can create the builder\n",
    "builder = tfds.builder('malaria', data_dir=\"C:\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some info about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the builder to extract a TensorFlow Dataset for efficient access to the images.\n",
    "We also split the dataset into training data for training the neural network parameters, and testing data for evaluating the network's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    train_ds, test_ds = (\n",
    "        builder.as_dataset(as_supervised=True, split=\"train[:80%]\"),\n",
    "        builder.as_dataset(as_supervised=True, split=\"train[-20%:]\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1** \n",
    "\n",
    "Plot some images from `train_ds` to get an idea of what the data looks like. Have a look at the [TensorFlow Datasets documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to see how you can *take* a number of images from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset two preprocessing operations are required:\n",
    "1. Resize all images to uniform width and height, and\n",
    "2. normalize the pixel value range to [0,1].\n",
    "\n",
    "Neural networks have a fixed architecture and can therefore only take inputs of equal dimensions. This is why we have to preprocess the images to have uniform dimensions. For the Malaria dataset, we downsample the images to be 40 pixels high and 40 pixels wide. We will need the `resize_with_pad` and `resize` functions from the `tf.image` module.\n",
    "\n",
    "Normalization of the pixel range to a [0,1] range is done to improve the stability of the weight updates. The Malaria dataset contains 8-bit RGB images, which have a maximum pixel value of 255 and a minimum of 0. If we would train the neural network using pixel values in the [0,255] range, the network's weights could grow too large causing high values during backpropagation and unstable training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the first preprocessing function\n",
    "# note: in this function we also cast the images to the float32 data type.\n",
    "\n",
    "image_width, image_height = 40, 40\n",
    "def resize_images(image, label):\n",
    "    return (\n",
    "        tf.cast(tf.image.resize_with_pad(tf.image.resize(image, (image_width, image_height)), image_width, image_height), tf.float32), \n",
    "        tf.cast(label, tf.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the second preprocessing function\n",
    "def minmax_normalization(image, label):\n",
    "    return (\n",
    "        image / tf.math.reduce_max(tf.reshape(image, [-1, image.shape[-1]]), axis=0), # divide each pixel in the image by the maximum value in each channel (R, G, and B)\n",
    "        label\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2** \n",
    "\n",
    "Apply both preprocessing functions to the train and test dataset defined earlier. Have a look at the [TensorFlow Datasets documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to see how you can *map* a function over the elements of a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now preprocessed and ready to handled by the neural network that we will define in the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a neural network architecture for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a neural network that is capable of classifying cell images in a positive and negative class. In this case, we want it to distinguishing between a healthy and parasitized cell based on a 40x40 RGB image. For today's standards this specific problem is a fairly easy computer vision task. A simple (and efficient) _shallow_ convolutional neural network (CNN) will suffice.\n",
    "\n",
    "## CNN Architecture\n",
    "\n",
    "The neural network will consist out of 4 main layers: 2 feature extraction layers, and 2 classification layers.\n",
    "\n",
    "### Feature extraction\n",
    "\n",
    "The feature extraction layers will learn to extract relevant features from the image. These features enable the classification layers to learn to classify cells into the healthy or parasitized category. The feature extraction layers are made up of convolution and max-pooling operations, and activation functions.\n",
    "\n",
    "![Convolution](images/convolution_overview.gif \"convolution\")\n",
    "![Max pooling](images/maxpool_animation.gif \"maxpool\")\n",
    "\n",
    "(from https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks?hl=ru)\n",
    "\n",
    "### Classification \n",
    "\n",
    "The extracted features get passed on to the classification layers. These are made up of densely connected layers, dropout connections and activation functions.\n",
    "\n",
    "![Dropout](images/dropout.gif \"dropout\")\n",
    "\n",
    "(from https://nagadakos.github.io/2018/09/23/dropout-effect-discussion/)\n",
    "\n",
    "### Activation functions\n",
    "\n",
    "The activation functions used in this neural network are the sigmoid, and Rectified Linear Unit (ReLU). \n",
    "![ReLU](images/relu.png \"ReLU\")\n",
    "\n",
    "The ReLU is used as the intermediate activation function in the feature extraction and classification layers. This function is used in many state-of-the-art image classification networks. It works well because it prevents the gradients from *vanishing* during backpropagation. The SELU activation is also frequently used, and adds some theoretical convergence guarantees.\n",
    "\n",
    "![Sigmoid](images/sigmoid.png \"Sigmoid\")\n",
    "\n",
    "The sigmoid is the activation function applied to the output of the final densely connected layer. It squeezes whatever value comes out of the network to the 0-1 range. Ideal, for binary classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture diagram\n",
    "\n",
    "![SegmentLocal](images/network-page-001.jpg \"Network diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3** \n",
    "\n",
    "Define a CNN architecture with the [TensorFlow Keras API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) using the above scheme as a guideline. Feel free to try out some of your own settings! The network takes RGB images as input, and has one output neuron that will produce output values between 0 (malaria) and 1 (healthy).\n",
    "\n",
    "You will need the following layers:\n",
    "- `tf.keras.layers.Conv2D`\n",
    "- `tf.keras.layers.MaxPool2D`\n",
    "- `tf.keras.layers.ReLU`\n",
    "- `tf.keras.layers.Flatten`\n",
    "- `tf.keras.layers.Dense`\n",
    "- `tf.keras.layers.Dropout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the loss function, optimizer, and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the parameters of the network we need an optimization algorithm, and a loss function to minize. In this particular case the binary cross-entropy is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bce_loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As optimization algorithm we choose stochastic gradient descent (SGD). More advanced optimizers exist, but SGD is a good first choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary cross-entropy is a good metric for optimization, but is less interpretable. Accuracy is a more intuitive metric for assessing model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    accuracy_metric = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, TensorFlow requires us to `compile` all parts of the learning procedure together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    classifier.compile(optimizer=sgd_optimizer, loss=bce_loss, metrics=[accuracy_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run learning procedure to train the network's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define some constants for the learning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 30 # How many times will the network see all training data\n",
    "batch_size = 256 # How many instances will the network process in one iteration\n",
    "\n",
    "train_len = int(builder.info.splits[\"train\"].num_examples*0.8)\n",
    "test_len = int(builder.info.splits[\"train\"].num_examples*0.2)\n",
    "steps_per_epoch = train_len//batch_size\n",
    "test_steps = test_len//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we iteratively update the parameters of the network using mini-batches of data (of size `batch_size`). In other words, we fit the network to the data. In pseudo-code:\n",
    "```\n",
    "for epoch in epochs:\n",
    "    for true_labels, batch in batches:\n",
    "        predictions = network(batch)\n",
    "        loss = loss_function(true_labels, predictions)\n",
    "        optimizer.update(network, loss)\n",
    "```\n",
    "The TensorFlow Keras API has several utitility functions that wrap basic procedures in helper functions. One such function is `fit` ([documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit)). It performs something close to the above pseudo-code on our network. All we have to do, is pass it the constants we defined above. Using helper functions is good practice as it lets us write code quicker, and it is less error-prone. However, always know what the helper functions do exactly!\n",
    "\n",
    "Note that we save the return value of the fit function to a variable. It contains important information about the performance of our network. We will analyze this in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    history = classifier.fit(\n",
    "        train_ds.batch(batch_size).repeat(), # on which data to we want to train\n",
    "        epochs=30, # how many epochs do we want to run\n",
    "        steps_per_epoch=steps_per_epoch, # how many steps are in one epoch\n",
    "        validation_data=test_ds.batch(batch_size).repeat(), # what test data do we want to use\n",
    "        validation_steps=test_steps # how many steps do we need to take when testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5**\n",
    "\n",
    "Before doing this task, go to [Inspect classifier performance](#Inspect-classifier-performance). Afterwards, return to this task.\n",
    "\n",
    "For now, we have used the SGD optimizer. Many other optimizers exist, such as the Adam optimizer. This optimizer combines two extensions of SGD into one powerful optimizer. Try to use the Adam optimizer to fit the neural network. See how the training progresses, do you notice any difference compared to SGD?\n",
    "\n",
    "**NOTE**: In order to retrain the classifier with another optimizer you have to reinstantiate the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect classifier performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the network, we are interested in its eventual performance and how this evolved during the fitting procedure. By comparing metrics computed on the training and test dataset we can spot overfitting as well: if the training accuracy is much higher compared to testing, the network is overfitting.\n",
    "\n",
    "The information we need, is returned by the fit function in a [`History`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History) object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 6** \n",
    "\n",
    "Plot the the accuracy and loss in function of the epochs for the train and validation set. Use the history object, returned by the `fit` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 6**\n",
    "\n",
    "Use the trained network to compute prediction scores for the test dataset. Use these scores to compute the confusion matrix and ROC AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: A look at intermediate representations of the network\n",
    "\n",
    "As an image passes through our convolutional neural network, it is transformed by the operations defined in the layers. Each transformation extracts the most relevant information from the input it receives, and passes it on to the next layer. The output of each intermediate layer is called a feature map or *representation*.\n",
    "\n",
    "By recording these intermediate representations for an image, we get an idea of what the network is focusing on to make its prediction. This way, we get some insight into the so-called *black-box model*.\n",
    "\n",
    "In this last part we will look at some of the representations learned by the network we trained. Before running the code, think about what these representations might look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some images to analyse\n",
    "n_images = 10\n",
    "it = iter(test_ds.batch(n_images))\n",
    "images, labels = next(it)\n",
    "\n",
    "# get the predictions\n",
    "predictions = classifier.predict(images)\n",
    "\n",
    "# record the intermediate representations\n",
    "representations = []\n",
    "record = [1, 2, 3]\n",
    "x = images\n",
    "for i, layer in enumerate(classifier.layers):\n",
    "    x = layer(x)\n",
    "    if i in record:\n",
    "        representations.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1+len(representations), len(images), figsize=(40, 10), constrained_layout=True)\n",
    "    \n",
    "for ax,img,label,prediction in zip(axes[0, :], images, labels, predictions):\n",
    "    ax.imshow(img)\n",
    "    txt_label = \"Healthy\" if label.numpy() == 1 else \"Malaria\"\n",
    "    txt_pred = \"Healthy\" if prediction > 0.5 else \"Malaria\"\n",
    "    ax.set_title(f\"{txt_label}, ({txt_pred})\")\n",
    "    \n",
    "for reps, row in zip(representations, axes[1:, :]):\n",
    "    for rep, ax in zip(reps, row):\n",
    "        ax.imshow(rep[..., 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
